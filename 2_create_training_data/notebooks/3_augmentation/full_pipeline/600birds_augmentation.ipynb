{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation for 600birds xeno-canto files\n",
    "\n",
    "We have downloaded the xeno-canto recordings from 600+ species of common North American birds, split them into ~6s files (see `../1_splitting`), and then detected which files are silent and which are not (see `../2_silence_detection/`).\n",
    "\n",
    "We will now:\n",
    "* Identify which species to create a training set from (based on how many non-silent training files are available)\n",
    "* Separate the data into train & test sets (where the train & test set do not contain split files that originated from the same long file)\n",
    "* Perform augmentations on each training file:\n",
    "    - Directly create one spectrogram image of the training file\n",
    "    - Create two randomly \"augmented\" spectrograms of the training file\n",
    "* Create spectrograms of each test file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify species of interest\n",
    "\n",
    "We want to exclude any species for which we do not have enough training data.\n",
    "\n",
    "Load the silence-detection results, set a threshold for the number of non-silent 6s files we need for each species, then create a list of species that have enough files to be included in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def count_non_silences(silence_csv, silence_col, count_num):\n",
    "    '''\n",
    "    Count the number of non-silent files\n",
    "    \n",
    "    Args:\n",
    "        silence_csv (string): path to csv containing\n",
    "            two columns, one of filenames and one of silences\n",
    "        silence_col (string): the name of the column\n",
    "            in the csv that contains silence information\n",
    "        count_num (int): the integer that we should\n",
    "            count as being non-silent\n",
    "    '''\n",
    "    \n",
    "    files = pd.read_csv(silence_csv, usecols = [silence_col])\n",
    "    return files[silence_col].tolist().count(count_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# The directory containing split files: split_top_dir/<species_name>/<split_files>\n",
    "split_top_dir = 'xeno-canto-splits'\n",
    "\n",
    "# All silence csvs\n",
    "csvs = glob.glob(split_top_dir + \"**/*.csv\")\n",
    "\n",
    "# Count number of non-silent files for each species csv\n",
    "num_silences_dict = {}\n",
    "for csv in csvs:\n",
    "    species = csv.split('/')[1]\n",
    "    num_silences_dict[species] = count_non_silences(\n",
    "        silence_csv = csv, silence_col = 'silent', count_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acanthis-flammea', 'acanthis-hornemanii']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of files required to keep this species in the model\n",
    "num_files_threshold = 1\n",
    "\n",
    "# Generate list of species to keep\n",
    "keep_spp = []\n",
    "for key, val in num_silences_dict.items():\n",
    "    if val > num_files_threshold:\n",
    "        keep_spp.append(key)\n",
    "keep_spp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "The train set and the test set should not overlap in source files. That means, they should not contain split files that originated from the same long file.\n",
    "\n",
    "TODO: this currently splits based on number of UNSPLIT files, not number of split files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# The directory containing unsplit files: split_top_dir/<species_name>/mp3s/<unsplit_files>\n",
    "unsplit_top_dir = 'xeno-canto'\n",
    "extension = '.txt' #For testing; change to mp3 or wav depending on filetypes\n",
    "\n",
    "# Percentage of unsplit files to use as sources for the training set\n",
    "train_size = 0.8\n",
    "seed = 22\n",
    "random.seed(seed)\n",
    "\n",
    "# Create dictionary pairing species names with lists of files to use for train/test set\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "for sp in keep_spp: \n",
    "    all_files = glob.glob(f'{unsplit_top_dir}/{sp}/mp3s/*{extension}')\n",
    "    num_train_files = math.floor(len(all_files)*train_size)\n",
    "    random.shuffle(all_files)\n",
    "    train_set_dict[sp] = all_files[:num_train_files]\n",
    "    test_set_dict[sp] = all_files[num_train_files:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acanthis-flammea': ['xeno-canto/acanthis-flammea/mp3s/395211.txt'],\n",
       " 'acanthis-hornemanii': ['xeno-canto/acanthis-hornemanii/mp3s/93659.txt']}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acanthis-flammea': ['xeno-canto/acanthis-flammea/mp3s/243939.txt'],\n",
       " 'acanthis-hornemanii': ['xeno-canto/acanthis-hornemanii/mp3s/92045.txt']}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split_files_dict(split_top_dir, unsplit_dict, extension):\n",
    "    '''\n",
    "    From dict of unsplit files, generate dict of split files\n",
    "    \n",
    "    Args:\n",
    "        split_top_dir (str): top directory containing\n",
    "            species directories and split files\n",
    "        unsplit_dict (dict): dictionary with keys = species\n",
    "            and values = filenames of unsplit files.\n",
    "            Unsplit filenames must be of the format\n",
    "            <split_top_dir>/<species>/<id_num>*<extension>\n",
    "        extension (str): filename extension\n",
    "    '''\n",
    "\n",
    "\n",
    "    split_files_dict = {}\n",
    "    for sp, files in unsplit_dict.items():\n",
    "        split_files = []\n",
    "\n",
    "        for file in files:\n",
    "            id_num = file.strip(extension).split(os.sep)[-1]\n",
    "            split_files.extend(glob.glob(f'{split_top_dir}/{sp}/{id_num}*{extension}'))\n",
    "\n",
    "        split_files_dict[sp] = split_files\n",
    "    \n",
    "    return split_files_dict\n",
    "\n",
    "    \n",
    "# Create list of split files based on source file ID numbers\n",
    "train_files_dict = make_split_files_dict(split_top_dir, train_set_dict, extension)\n",
    "test_set_dict = make_split_files_dict(split_top_dir, test_set_dict, extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform augmentations on each training file\n",
    "\n",
    "Three training images should be created for each training file. One should be a true copy of the training file. Two others should be randomly augmented spectrograms of the training file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spectrograms of each test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup to import from other dirs\n",
    "import sys\n",
    "import os\n",
    "REPO_PATH = os.path.abspath('../../..')\n",
    "sys.path.append(REPO_PATH)\n",
    "\n",
    "# Augmentation modules\n",
    "import create_training_data.code.audio_aug as aa\n",
    "import create_training_data.code.spectrogram_aug as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spect(spect, spect_path):\n",
    "    '''\n",
    "    Save spectrogram image and return its metadata\n",
    "    \n",
    "    Args:\n",
    "        spect (Spectrogram object): spectrogram\n",
    "            object to save--must be in PIL format\n",
    "        spect_path (string): path at which to save\n",
    "            spectrogram image\n",
    "            \n",
    "    Returns:\n",
    "        dictionary of metadata about image, etc.\n",
    "    '''\n",
    "    \n",
    "    # Save image\n",
    "    spect.save_image(path = spect_path)\n",
    "    \n",
    "    # Create a dictionary for metadata\n",
    "     metadata_dict = {\n",
    "        'path':spect.save_path,\n",
    "        'manipulations':spect.manipulations,\n",
    "        'sources':spect.sources,\n",
    "    }\n",
    "        \n",
    "    # Add information about what audio labels were in file \n",
    "    for label in label_dict.keys():\n",
    "        metadata_dict[label] = int(label in spect.labels)\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_file(path, label, label_dict):\n",
    "    \n",
    "    audio = (\n",
    "        aa.Audio(path = path, label = label)\n",
    "            .apply(func = aa.get_chunk)\n",
    "            .apply(func = aa.get_chunk)\n",
    "            .apply(func = aa.cyclic_shift)\n",
    "            .apply(func = aa.time_stretch_divisions)\n",
    "            .apply(func = aa.pitch_shift_divisions)\n",
    "            .apply(func = aa.random_filter)\n",
    "            .apply(func = aa.sum_chunks,\n",
    "                label_dict = label_dict)\n",
    "            .apply(func = aa.sum_chunks,\n",
    "                label_dict = label_dict)\n",
    "    )\n",
    "    \n",
    "    spect = (\n",
    "        sa.Spectrogram(audio = audio)\n",
    "            .apply(func = sa.make_linear_spectrogram)\n",
    "            .apply(func = sa.remove_random_hi_lo_bands)\n",
    "            .apply(func = sa.resize_random_bands, rows_or_cols = 'rows')\n",
    "            .apply(func = sa.resize_random_bands, rows_or_cols = 'cols')\n",
    "            .apply(func = sa.resize_spect_random_interpolation, width = 299, height = 299)\n",
    "            .apply(func = sa.color_jitter, hue = None)\n",
    "        )\n",
    "    \n",
    "    return spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_spects(path, label, label_dict, save_dir, num_manips = 2):\n",
    "    '''\n",
    "    Create one pristine and multiple manipulated spectrograms from an audio file\n",
    "    \n",
    "    Creates an unmanipulated spectrogram and a chosen number of\n",
    "    manipulated spectrograms from an audio file\n",
    "    \n",
    "    Args:\n",
    "        path (str): path to 6s-long audio file\n",
    "        label (str): label for this audio file\n",
    "        save_dir (str): directory in which to save results\n",
    "        num_manips (str): number of manipulated \n",
    "            spectrograms to create (default 2)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Create unmanipulated spectrogram\n",
    "    unmanipulated_spect = aa.Audio(path = path, label = label).apply(func = aa.get_chunk)\n",
    "    unmanipulated_spect = (\n",
    "        sa.Spectrogram(audio = unmanipulated_spect)\n",
    "            .apply(func = sa.make_linear_spectrogram)\n",
    "            .apply(func = sa.resize_spect_random_interpolation,\n",
    "                   width=299, height=299,\n",
    "                   chance_random_interpolation = 0)\n",
    "    )\n",
    "\n",
    "    # Create manipulated spectrograms\n",
    "    manipulated_spects = []\n",
    "    for _ in num_manips:\n",
    "        manipulated_spect = augment_file(path = path, label = label, label_dict = label_dict)\n",
    "        manipulated_spects.append(manipulated_spect)\n",
    "    \n",
    "    # Create columns for csv about spectrogram\n",
    "    df = pd.DataFrame(columns=['path', 'manipulations', 'sources', *label_dict.keys()])\n",
    "    \n",
    "    # Save spectrogram and add to csv columns\n",
    "    id_num = # TODO: Extract ID number from `path` in a stable way\n",
    "    metadata = save_spect(unmanipulated_spect, filename = os.path.join(save_dir, f'{id}_unmanipulated.png'))\n",
    "    df = df.append(metadata, ignore_index=True)\n",
    "    for idx, spect in enumerate(manipulated_spects):\n",
    "        metadata = save_spect(spect, filename = os.path.join(save_dir, f'{id}_manipulated_{idx}.png'))\n",
    "        df = df.append(metadata, ignore_index=True)\n",
    "    \n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (birds)",
   "language": "python",
   "name": "birds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
